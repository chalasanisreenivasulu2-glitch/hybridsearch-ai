# ============================================
# HybridSearch AI - Environment Configuration
# ============================================
# 
# SETUP INSTRUCTIONS:
# 1. Copy this file to .env:  Copy-Item .env.example .env
# 2. Replace all placeholder values with your actual keys
# 3. Never commit .env to git (it's in .gitignore)
# 4. Keep .env.example in git for team reference
#
# ============================================

# ============================================
# API KEYS (REQUIRED)
# ============================================

# Serper API - Web Search Engine
# Get your key at: https://serper.dev/
# Free tier: 2,500 searches/month
SERPER_API_KEY=your_serper_api_key_here

# Groq API - Fast AI Inference (Recommended)
# Get your key at: https://console.groq.com/
# Free tier: Very generous limits
GROQ_API_KEY=your_groq_api_key_here

# OpenAI API - Most Accurate AI (Optional)
# Get your key at: https://platform.openai.com/
# Note: This is a paid service
OPENAI_API_KEY=your_openai_api_key_here

# ============================================
# FLASK CONFIGURATION
# ============================================

# Flask Secret Key - Generate with: python -c "import secrets; print(secrets.token_hex(32))"
# This is used for session encryption
FLASK_SECRET_KEY=generate_random_secret_key_here

# Flask Environment
# Options: development, production
FLASK_ENV=development

# Flask Debug Mode
# Set to False in production
FLASK_DEBUG=True

# ============================================
# APPLICATION SETTINGS
# ============================================

# Cache Duration (in seconds)
# How long to cache search results
# Default: 3600 (1 hour)
CACHE_DURATION=3600

# Maximum History Items
# How many searches to keep in history
# Default: 10
MAX_HISTORY=10

# ============================================
# AI MODEL CONFIGURATION
# ============================================

# Local Model (Ollama)
# Model to use when running locally
# Must be installed via: ollama pull <model>
LOCAL_MODEL=llama2

# Groq Model
# Available models:
# - llama-3.3-70b-versatile (Best quality, recommended)
# - llama-3.1-8b-instant (Faster, smaller)
# - mixtral-8x7b-32768 (Alternative)
GROQ_MODEL=llama-3.3-70b-versatile

# OpenAI Model
# Available models:
# - gpt-4o (Most capable, expensive)
# - gpt-4o-mini (Fast and affordable, recommended)
# - gpt-3.5-turbo (Cheaper, older)
OPENAI_MODEL=gpt-4o-mini

# ============================================
# RATE LIMITING (Optional - edit in app.py)
# ============================================
# These are set in app.py code, not here
# RATE_LIMIT_SEARCHES = 50  # searches per hour
# RATE_LIMIT_WINDOW = 3600  # window in seconds

# ============================================
# ADVANCED SETTINGS (Optional)
# ============================================

# Server Host
# Use 0.0.0.0 to allow external connections
# Use 127.0.0.1 for localhost only
FLASK_HOST=0.0.0.0

# Server Port
FLASK_PORT=5000

# ============================================
# NOTES
# ============================================
#
# API Key Sources:
# - Serper: https://serper.dev/signup
# - Groq: https://console.groq.com/keys
# - OpenAI: https://platform.openai.com/api-keys
#
# Generate Flask Secret:
# python -c "import secrets; print(secrets.token_hex(32))"
#
# Verify Setup:
# python -c "from dotenv import load_dotenv; import os; load_dotenv(); print('✅' if os.getenv('SERPER_API_KEY') else '❌', 'Serper'); print('✅' if os.getenv('GROQ_API_KEY') else '❌', 'Groq')"
#
# ============================================